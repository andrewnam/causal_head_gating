{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeffbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4edace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"projects/causal_head_gating/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "directories = {k: Path(v) for k, v in config['directories'].items()}\n",
    "\n",
    "os.environ['HF_HOME'] = str(config['directories']['huggingface'])\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f5848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>target</th>\n",
       "      <th>pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flow^ started^ flow\\n lungs^ feel^ lungs\\n ha...</td>\n",
       "      <td>prince</td>\n",
       "      <td>ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acid^ havoc^ acid\\n slow^atter^ slow\\n dark^ ...</td>\n",
       "      <td>breathe</td>\n",
       "      <td>ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think^ blood^ think\\n penalty^ name^ penalty\\...</td>\n",
       "      <td>yang</td>\n",
       "      <td>ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slow^ mouse^ slow\\n citizen^ filled^ citizen\\...</td>\n",
       "      <td>without</td>\n",
       "      <td>ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tell^ legs^ tell\\nland^ reaction^land\\n stop^...</td>\n",
       "      <td>erry</td>\n",
       "      <td>ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>ver^ contact^ contact\\n week^ones^ones\\n suppo...</td>\n",
       "      <td>collect</td>\n",
       "      <td>ABB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>prison^ help^ help\\n boots^ain^ain\\n they^ tr...</td>\n",
       "      <td>hair</td>\n",
       "      <td>ABB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>steps^ needles^ needles\\n seams^ogh^ogh\\n fol...</td>\n",
       "      <td>thread</td>\n",
       "      <td>ABB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>man^kit^kit\\n core^ measures^ measures\\n same^...</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>ABB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>utherland^els^els\\n fall^ breath^ breath\\n ric...</td>\n",
       "      <td>dance</td>\n",
       "      <td>ABB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   prompt     target pattern\n",
       "0        flow^ started^ flow\\n lungs^ feel^ lungs\\n ha...     prince     ABA\n",
       "1        acid^ havoc^ acid\\n slow^atter^ slow\\n dark^ ...    breathe     ABA\n",
       "2        think^ blood^ think\\n penalty^ name^ penalty\\...       yang     ABA\n",
       "3        slow^ mouse^ slow\\n citizen^ filled^ citizen\\...    without     ABA\n",
       "4        tell^ legs^ tell\\nland^ reaction^land\\n stop^...       erry     ABA\n",
       "...                                                   ...        ...     ...\n",
       "199995  ver^ contact^ contact\\n week^ones^ones\\n suppo...    collect     ABB\n",
       "199996   prison^ help^ help\\n boots^ain^ain\\n they^ tr...       hair     ABB\n",
       "199997   steps^ needles^ needles\\n seams^ogh^ogh\\n fol...     thread     ABB\n",
       "199998  man^kit^kit\\n core^ measures^ measures\\n same^...   tomorrow     ABB\n",
       "199999  utherland^els^els\\n fall^ breath^ breath\\n ric...      dance     ABB\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv(directories['repo'] / 'data/aba_abb.tsv', sep='\\t')\n",
    "texts = list(df_data.prompt + df_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e0063a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0e8cbc2b784052a3c7928860dbee87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing meta-llama/Llama-3.2-3B-Instruct\n",
      "Saving to /scratch/gpfs/JDC/andrew/chg/datasets/aba_abb/meta-llama/Llama-3.2-3B-Instruct/train.pt\n",
      "Tokenizing meta-llama/Llama-3.2-3B\n",
      "Saving to /scratch/gpfs/JDC/andrew/chg/datasets/aba_abb/meta-llama/Llama-3.2-3B/train.pt\n",
      "Tokenizing meta-llama/Llama-3.2-1B\n",
      "Saving to /scratch/gpfs/JDC/andrew/chg/datasets/aba_abb/meta-llama/Llama-3.2-1B/train.pt\n",
      "Tokenizing meta-llama/Llama-3.1-8B\n",
      "Saving to /scratch/gpfs/JDC/andrew/chg/datasets/aba_abb/meta-llama/Llama-3.1-8B/train.pt\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'meta-llama/Llama-3.2-3B-Instruct',\n",
    "    'meta-llama/Llama-3.2-3B',\n",
    "    'meta-llama/Llama-3.2-1B',\n",
    "    'meta-llama/Llama-3.1-8B',\n",
    "]\n",
    "\n",
    "for model_name in tqdm(model_names):\n",
    "    print(f\"Tokenizing {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    tokens = tokenizer(texts)['input_ids']\n",
    "    input_ids = torch.tensor(tokens)\n",
    "    loss_masks = torch.zeros_like(input_ids, dtype=bool)\n",
    "    loss_masks[:,-1] = 1  # only compute loss on the last token\n",
    "    dataset = {\n",
    "        'input_ids': input_ids,\n",
    "        'loss_masks': loss_masks,\n",
    "    }\n",
    "    \n",
    "    save_path = Path(directories['save']) / f'datasets/aba_abb/{model_name}/train.pt'\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Saving to {save_path}\")\n",
    "    torch.save(dataset, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_ablation",
   "language": "python",
   "name": "llm_ablation"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
